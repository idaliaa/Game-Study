{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036069af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from nltk import download\n",
    "# If necessary, download the required NLTK packages --> \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c101b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load CSV data\n",
    "df = pd.read_csv('cleaned_youtube_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca40f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Function to generate n-grams\n",
    "def generate_ngrams(text, n):\n",
    "    if pd.isna(text) or len(text.strip()) == 0:\n",
    "        return []  # Return empty list for empty comments\n",
    "    words = word_tokenize(text)\n",
    "    return list(ngrams(words, n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed49cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will generate lists of n-grams for each comment\n",
    "df['2-grams'] = df['comment'].apply(lambda x: generate_ngrams(x, 2))\n",
    "df['3-grams'] = df['comment'].apply(lambda x: generate_ngrams(x, 3))\n",
    "df['4-grams'] = df['comment'].apply(lambda x: generate_ngrams(x, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4b6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the lists of n-grams into individual rows for counting\n",
    "all_2grams = df['2-grams'].explode().dropna()\n",
    "all_3grams = df['3-grams'].explode().dropna()\n",
    "all_4grams = df['4-grams'].explode().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dea525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert n-grams from tuple to string format (so they can be counted)\n",
    "all_2grams = all_2grams.apply(lambda x: ' '.join(x))\n",
    "all_3grams = all_3grams.apply(lambda x: ' '.join(x))\n",
    "all_4grams = all_4grams.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db25864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first few n-grams to ensure they're correct\n",
    "print(\"First 5 2-grams:\")\n",
    "print(all_2grams.head())\n",
    "print(\"First 5 3-grams:\")\n",
    "print(all_3grams.head())\n",
    "print(\"First 5 4-grams:\")\n",
    "print(all_4grams.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e340ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the most common n-grams\n",
    "counter_2grams = Counter(all_2grams)\n",
    "counter_3grams = Counter(all_3grams)\n",
    "counter_4grams = Counter(all_4grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c708e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the counter objects\n",
    "df_2grams = pd.DataFrame(counter_2grams.most_common(100), columns=['2-gram', 'Frequency'])\n",
    "df_3grams = pd.DataFrame(counter_3grams.most_common(100), columns=['3-gram', 'Frequency'])\n",
    "df_4grams = pd.DataFrame(counter_4grams.most_common(100), columns=['4-gram', 'Frequency'])\n",
    "\n",
    "# Optionally, save the DataFrames as CSVs\n",
    "df_2grams.to_csv('top_2grams.csv', index=False)\n",
    "df_3grams.to_csv('top_3grams.csv', index=False)\n",
    "df_4grams.to_csv('top_4grams.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Counter is working properly\n",
    "print(\"Most common 2-grams:\")\n",
    "print(counter_2grams.most_common(10))\n",
    "\n",
    "print(\"Most common 3-grams:\")\n",
    "print(counter_3grams.most_common(10))\n",
    "\n",
    "print(\"Most common 4-grams:\")\n",
    "print(counter_4grams.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a new CSV\n",
    "df.to_csv('n-gram_youtube_comments.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ad19da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words across all comments: 1249752\n"
     ]
    }
   ],
   "source": [
    "# Function to count words in a comment\n",
    "def count_words(text):\n",
    "    if pd.isna(text) or len(text.strip()) == 0:\n",
    "        return 0  # Return 0 if comment is empty or NaN\n",
    "    words = word_tokenize(text)\n",
    "    return len(words)\n",
    "\n",
    "# Apply the function to the 'comment' column to count words for each comment\n",
    "df['word_count'] = df['comment'].apply(count_words)\n",
    "\n",
    "# Get the total word count across all comments\n",
    "total_word_count = df['word_count'].sum()\n",
    "print(f'Total number of words across all comments: {total_word_count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kafka-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
